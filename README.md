# Computer Vision-Based Path-Planning with Indoor Low-Cost Autonomous Drones: An Educational Surrogate Project for Autonomous Wind Farm Navigation
Angel Rodriguez, Mohammad Shekaramiz, and Mohammad A.S. Masoum<br />

![alt text](https://github.com/MoShekaramiz/Tello_Edu_Surrogated_Wind_Fram/blob/main/Readme_img/UVU_engineering.png "UVU Logo")

The branch was developed by Mr. Angel Rodriguez, ECE student at UVU, supervised by Dr. Mohammad Shekaramiz 

If using repository, give credit to the following paper:

Computer Vision-Based Path-Planning with Indoor Low-Cost Autonomous Drones: An Educational Surrogate Project for Autonomous Wind Farm Navigation - 2024

This work is supported by the Office of the Commissioner of Utah System of Higher Education (USHE)-Deep Technology Initiative Grant 20210016UT

![alt text](https://github.com/MoShekaramiz/Tello_Edu_Surrogated_Wind_Fram/blob/main/Readme_img/USHE-logo.png "USHE Logo")
    
## Table of Contents
1. [Purpose](#Purpose)
2. [Installations](#Installations)
3. [Usage](#Usage)
4. [movement.py Instructions](#movement.py-Instructions)
    1. [User Commands](#User-Commands)
        1. [Initialization](#Initialization)
        2. [move()](#move())
        3. [go_to()](#go_to())
        4. [curve()](#curve())
        5. [video()](#video())
        6. [get_location()](#get_location())
        7. [get_x_location()](#get_x_location())
        8. [get_y_location()](#get_y_location())
        9. [get_z_location()](#get_z_location())
        10. [get_angle()](#get_angle())
        11. [get_drone()](#get_drone())
        12. [get_video()](#get_video())
    2. [Other Commands](#Other-Commands)
        1. [get_turbine_locations()](#get_turbine_locations())
        2. [append_turbine_locations()](#append_turbine_locations())
        3. [target_angle()](#target_angle())
5. [output.py Instructions](#output.py-Instructions)
    1. [stop_haar()](#stop_haar())
    2. [start_haar()](#start_haar())
    3. [stop_qr()](#stop_qr())
    4. [start_qr()](#start_qr())
    5. [stop_image()](#stop_image())
6. [area_exploration.py Instructions](#area_exploration.py-Instructions)
    1. [snake_exploration()](#snake_exploration())
    2. [spiral_exploration()](#spiral_exploration())
7. [downvision_calibration.py Instructions](#downvision_calibration.py-Instructions)
    1. [calibrate()](#calibrate())
8. [traveling_salesman_geometric.py Instructions](#traveling_salesman_geometric.py-Instructions)
    1. [TravelingSalesman()](#TravelingSalesman())
        1. [plot()](#plot())
        2. [get_path()](#get_path())
        3. [energy_calc()](#energy_calc())

## Purpose <a name="Purpose"></a>

<details><summary>Purpose</summary>
<p>
    
This case study shows the initial results of aiming to reduce the cost, man-hours, and safety risks involved with the external structural inspection process of wind turbines using a fully automated drone-based system. The end goal is to use object detection and path planning algorithms to automate the process of identifying a specific wind turbine in the field via a drone, safely approaching the wind turbine, and capturing the images necessary for analysis and inspection. Our case study here serves as a small-scale proof of concept for the path planning solutions using pedestal fans in the place of wind turbines and a Tello EDU drone. Our study demonstrates the success of the drone in autonomously exploring the region of interest, detecting the desired fan, safely approaching the fan, verifying the fan via scanning the associated QR code, capturing video and images from multiple angles, and safely flying back to the starting point to land.

[![UVU Drone Path Planning Capstone](http://img.youtube.com/vi/POtHoBgGE8U/0.jpg)](http://www.youtube.com/watch?v=POtHoBgGE8U)

</p>
</details>

## Intallations <a name="Installations"></a>

<details><summary>Installations</summary>
<p>
    
This application uses:<br />
Python 3.11.1<br />
OpenCV 4.9.0.80<br />
djitellopy 2.5.0<br />
matplotlib 3.8.3<br />
numpy 1.26.4<br />
PyQRCode 1.2.1<br />

```python
pip install opencv-python djitellopy matplotlib numpy pyqrcode
```
See [djitellopy.readme.md](https://github.com/damiafuentes/DJITelloPy/blob/master/README.md) for more information on djitellopy.<br />
See [opencv-python 4.5.5.64](https://pypi.org/project/opencv-python/) for more information on OpenCV.<br />
See [Tello SDK 2.0 User Guide](https://dl-cdn.ryzerobotics.com/downloads/Tello/Tello%20SDK%202.0%20User%20Guide.pdf) for more information on the Tello EDU SDK.<br />

## Usage <a name="Usage"></a>
### Running the current setup
To run the program in its current configuration, launch area_exploration.py in your IDE of choice. 
The current iteration of the program will begin a snaking exploration pattern while looking for black metallic fans.
If a fan is detected, the drone will fly up to the fan, lower 80cm, and scan the QR code.
The drone will then fly the pre-selected mission, which defaults to filming the front of the fan for 10 seconds in mp4 format.
After finding the correct target and completing the mission, the drone will fly back to the starting point and land itself.
<br />
<br />

</details>

## movement.py Instructions <a name="movement.py-Instructions"></a>
The following instructions are for the use of our movement.py class for other automated drone purposes:

### Initialization <a name="Initialization"></a>
    
To initialize the drone, the movement class in movement.py will handle most of the required initialization steps.<br />
The initialization has 2 optional parameters: the altitude adjustment of the drone after takeoff (default to 40cm for a total of 90cm above the ground) and a boolean stream variable that will control if the user wants the live video feed (default to True, see the section on output_video.py for more details).<br />
Import movement.py into your Python code and assign a variable to the class as follows:
```python
import movement as mv
# Takeoff with default settings

drone = mv.movement()
```
OR
```python
import movement as mv
# Rise to 100cm on takeoff and no video stream

drone = mv.movement(100, False)
```
The user must power on the Tello EDU and connect to the drone via wi-fi. 
Instantiating the drone this way will begin the live video stream, launch the drone, raise the drone's altitude (set to a default of 90cm to choose a different height pass in an integer value), and prepare the drone for further commands.<br />
The drone's initial location is also initialized at the cartesian point (0,0), the current angle of the drone being 0째, and the altitude after takeoff using one of the drone's onboard attitude sensors.

---------------------------------------------------------------------------------------------------------------------
    


#### Commands from the user: <a name="User-Commands"></a>

The following is a comprehensive list of functions available to the user and their meaning:
| Function       | Inputs                                    | Result                                               |
| ---------------|:----------------------------------------- | :----------------------------------------------------|
| land           | none                                      | Lands the drone                                      |
| move           | fwd, back, up, down, left, right, ccw, cw | Moves the drone and tracks location                  |
| go_to          | targetx, targety, ending_angle, targetz   | Moves the drone to the chosen coordinates            |
| curve          | radius, left_right                        | Curves the drone left or right 90째                   |
| video          | none                                      | Starts the Livestream                                |
| get_location   | none                                      | Returns a list of the x, y, z coordinates and angle  |
| get_x_location | none                                      | Returns the drone's current x coordinate             |
| get_y_location | none                                      | Returns the drone's current y coordinate             |
| get_z_location | none                                      | Returns the drone's current z coordinate             |
| get_angle      | none                                      | Returns the drone's current angle                    |
| get_drone      | none                                      | Returns the class interfacing the drone with the SDK |
| get_video      | none                                      | Returns the variable controlling the livestream      |

    

#### land() <a name="land()"></a>

<details><summary>land</summary>
<p>
    
Lands the drone after turning off the video stream and printing a message directing the user to the directory any collected data has been stored in. The action then exits the program.
```python
drone.land()
```
    
</p>
</details>

#### move() <a name="move()"></a>

<details><summary>move()</summary>
<p>
    
Moves the drone according to the direction or angle given by the user. Movement must be in cm between 20cm and 500cm. The angle movement is in degrees from 0 to 359. Keywords for movement are: fwd(forward), back, up, down, left, right, ccw(counterclockwise rotation), cw(clockwise rotation).
```python
# Move forward 50cm

drone.move(fwd=50)
```
    
</p>
</details>

#### go_to() <a name="go_to()"></a>

<details><summary>go_to()</summary>
<p>
    
Tells the drone to go to a specific set of cartesian coordinates with a desired ending angle. The drone's coordinates after movement are printed for the user. The reason why the z-axis location is last in the parameters is because it is the least used of all 3 in our current development.
```python
# Go to xyz coordinates (100,150,300) with an ending angle of 141째

drone.go_to(100, 150, 141, 300)
```

</p>
</details>

#### curve() <a name="curve()"></a>

<details><summary>curve()</summary>
<p>
    
Rotates the drone 90째 in a curved path with a given radius and left/right flag to curve to the left or right. The default is a 50cm curve to the left. This function is still in work and may not always work as expected.
```python
# Curve right 100cm
# left_right=1 sets the curve right, the default is left

drone.curve(radius=100, left_right=1) 
```

</p>
</details>

#### video() <a name="video()"></a>

<details><summary>video()</summary>
<p>
    
Initializes a live video stream for the user. This function is called during the initialization process by default. If the user doesn't want a video stream, the stream parameter during initialization should be set to false. Please look at the section on using [output.py](#output.py-Instructions) for more information.
```python
# Start the live stream

drone.video()
```

</p>
</details>

#### get_location() <a name="get_location()"></a>

<details><summary>get_location()</summary>
<p>
    
Returns the full list of the drone's location formatted as [x_location, y_location, z_location, angle]. 
```python
location = drone.get_location()
```
    
</p>
</details>

#### get_x_location() <a name="get_x_location()"></a>

<details><summary>get_x_location()</summary>
<p>
    
Returns only the x location of the drone.
```python
x_location = drone.get_x_location()
```
    
</p>
</details>

#### get_y_location() <a name="get_y_location()"></a>

<details><summary>get_y_location()</summary>
<p>
    
Returns only the y location of the drone.
```python
y_location = drone.get_y_location()
```

</p>
</details>

#### get_z_location() <a name="get_z_location()"></a>

<details><summary>get_z_location()</summary>
<p>
    
Returns only the z location of the drone.
```python
z_location = drone.get_z_location()
```

</p>
</details>

#### get_angle() <a name="get_angle()"></a>

<details><summary>get_angle()</summary>
<p>
    
Returns only the angle of the drone.
```python
angle = drone.get_angle()
```

</p>
</details>

#### get_drone() <a name="get_drone()"></a>

<details><summary>get_drone()</summary>
<p>
    
Returns the class controlling the SDK for the drone should the user need it.
```python
drone = drone.get_drone()
```

</p>
</details>

#### get_video() <a name="get_video()"></a>

<details><summary>get_video()</summary>
<p>
    
Returns the variable controlling the video stream for the drone.
```python
video = drone.get_video()
```
    
</p>
</details>

------------------------------------------------------------------------------------------------------------------------------
### Commands not typically called by the user <a name="Other-Commands"></a>
The following list of commands are functions that are not typically called by the user but can be should the user decide it is necessary:
| Function                 | Inputs                                    | Result                                               |
| ------------------------ |:----------------------------------------- | :--------------------------------------------------- |
| get_turbine_locations    | none                                      | Returns a list of the turbines found by the drone    |
| append_turbine_locations | QR                                        | Adds a new turbine to the turbine_locations list     |
| target_angle             | return_angle, x, y, quadrant              | Rotates the drone shortest distance to the target    |

#### get_turbine_locations() <a name="get_turbine_locations()"></a>

<details><summary>get_turbine_locations()</summary>
<p>
    
Returns a list of the gathered locations and no-fly zones of turbines while the drone was in flight.
```python
turbines = drone.get_turbine_locations()
```
    
</p>
</details>

#### append_turbine_locations() <a name="append_turbine_locations()"></a>

<details><summary>append_turbine_locations()</summary>
<p>
    
Adds another turbine to the list according to its detected location and QR code data.
```python
# QR contains the string data from decrypting a QR code

drone.append_turbine_locations(QR)
```
    
</p>
</details>

#### target_angle() <a name="target_angle()"></a>

<details><summary>target_angle()</summary>
<p>
    
Takes the angle to the drone from the target location, the x and y coordinates of the target location, and the quadrant of the drone relative to the target location acting as the origin.
The drone will then rotate the shortest possible distance to center on the target location. It is recommended that the user instead use the go_to() or move() functions to rotate the drone instead of using target_angle().
```python
# If the drone were located at a 45-degree angle from the origin and was trying to return

drone.target_angle(45, 0, 0, 1)
```
</p>
</details>

## output.py Instructions <a name="output.py-Instructions"></a>
A livestream video is created during initialization of the drone unless manually set to False. The algorithm creates the Livestream class found in output.py. The video stream can be started later by using the [video()](#video()) command found under the [movement.py instructions](#movement.py-Instructions). The video stream is initialized to operate the Haar cascade detection algorithm and can also scan for QR codes in the frame. The easiest way to currently interact with the Livestream class in output.py is to use the [get_video()](#get_video()) command seen in the [movement.py instructions](#movement.py-Instructions), which returns the Livestream class. Use the commands below to interact with the Livestream:

| Function        | Inputs     | Result                            |
| --------------- |:---------- | :-------------------------------- |
| stop_haar       | none       | Stops the Haar cascade detection  |
| start_haar      | none       | Starts the Haar cascade detection |
| stop_qr         | none       | Stops the QR code detection       |
| start_qr        | none       | Starts the QR code detection      |
| stop_image      | none       | Stops the image output            |

#### stop_haar() <a name="stop_haar()"></a>

<details><summary>stop_haar()</summary>
<p>
    
Stops the Haar cascade detection algorithm. The detection is currently set to detect black metallic fans. If this is turned off, QR code detection immediately starts. The Haar cascade and QR detection must be turned off for a regular live stream.
```python
# Assign the class to a variable
video = drone.get_video()

# Disable the Haar cascade
video.stop_haar()
```

</p>
</details>

#### start_haar() <a name="start_haar()"></a>

<details><summary>start_haar()</summary>
<p>
    
Starts the Haar cascade detection algorithm. It will turn on immediately from a regular live stream, but if the QR detection is on, it must be deactivated to restart the Haar cascade. The Haar cascade is on by default after starting the live stream.
```python
# Assign the class to a variable
video = drone.get_video()

# Start the Haar cascade
video.start_haar()
```

</p>
</details>

#### stop_qr() <a name="stop_qr()"></a>

<details><summary>stop_qr()</summary>
<p>
    
Stops the QR code detection. Stopping the Haar cascade and QR detection will result in a regular livestream video. _It is recommended to use 64-bit Python when using QR code detection._
```python
# Assign the class to a variable
video = drone.get_video()

# Disable the QR detection
video.stop_qr()
```

</p>
</details>

#### start_qr() <a name="start_qr()"></a>

<details><summary>start_qr()</summary>
<p>
    
Starts the QR detection algorithm. It will turn on immediately from a regular livestream, but if the Haar cascade detection is on, it must be deactivated to restart the QR detection. The QR detection is on by default after starting the live stream and will show after deactivating the Haar cascade.
```python
# Assign the class to a variable
video = drone.get_video()

# Start the QR detection
video.start_qr()
```
    
</p>
</details>

#### stop_image() <a name="stop_image()"></a>

<details><summary>stop_image()</summary>
<p>
    
Turns off the livestream image. The Haar cascade and QR detection must also be turned off to stop the live stream fully. This is done automatically when [land()](#land()) is used from [movement.py](#movement.py-Instructions).
```python
# Assign the class to a variable
video = drone.get_video()

# Disable the QR detection
video.stop_qr()

# Disable the Haar cascade
video.stop_haar()

# Stop the livestream
video.stop_image()
```
    
</p>
</details>

## area_exploration.py Instructions <a name="area_exploration.py-Instructions"></a>
This file provides area exploration functionality to search for targets over an area of a preset size. Starting at coordinates (0,0), the drone will explore the area in either a snaking or spiral pattern chosen by the user.

#### snake_exploration() <a name="snake_exploration()"></a>

<details><summary>snake_exploration()</summary>
<p>
    
Have the drone explore an area of a preset size in a snaking pattern. If the drone doesn't find the target by the end of the spiral pattern, the drone returns to the launch point and lands.
```python
# Initialize the drone
import movement as mov
drone = mov.movement()

# Set the search boundaries as [minimum_x_value, maximum_x_value, minimum_y_value, maximum_y_value]
bounds = [0, 161, 0, 221]

# Set the search width between turns on the y-axis in centimeters
search_width = 50

# Set the movement increment on the x-axis in centimeters when the drone stops and check the camera for a target
move_increment = 75

# Initiate the snake exploration pattern
snake_exploration(drone, bounds, search_width, move_increment)

# Land and exit the program
drone.land()
```

</p>
</details>

#### spiral_exploration() <a name="spiral_exploration()"></a>

<details><summary>spiral_exploration()</summary>
<p>
    
Have the drone explore an area of a preset size in a spiral pattern. If the drone doesn't find the target by the end of the spiral pattern, the drone returns to the launch point and lands.
```python
# Initialize the drone
import movement as mov
drone = mov.movement()

# Set the search boundaries as [minimum_x_value, maximum_x_value, minimum_y_value, maximum_y_value]
bounds = [0, 161, 0, 221]

# Set the search width between turns on the y-axis in centimeters
search_width = 50

# Set the movement increment on the x-axis in centimeters when the drone stops and check the camera for a target
move_increment = 75

# Initiate the spiral exploration pattern
apiral_exploration(drone, bounds, search_width, move_increment)

# Land and exit the program
drone.land()
```

</p>
</details>

## downvision_calibration.py Instructions<a name="downvision_calibration.py-Instructions"></a>
This file allows the user to recalibrate the location and angle of the drone by positioning the drone first over a STARTRC UAV landing pad, as seen in the video below. 

[![Drone Location Calibration Test](http://img.youtube.com/vi/H2kWhc6m8rA/0.jpg)](http://www.youtube.com/watch?v=H2kWhc6m8rA)

Video created by Brandon Pinney, former ECE student at UVU

### calibrate() <a name="calibrate()"></a>

<details><summary>calibrate()</summary>
<p>
    
This function takes the drone class, a boolean value indicating if the drone is to land after the calibration, the new x_coordinate (default to x = 0), and the new y_coordinate (default to y = 0).
The drone will then lower to 30cm off the ground and use RC motor controls and Hough transforms to center over the helipad and recalibrate the location and angle of the drone.
```python
drone.go_to(0, 0, 0)
calibrate(drone, land=True, x_coordinate=0, y_coordinate=0)
```
    
</p>
</details>

## traveling_salesman_geometric.py Instructions<a name="traveling_salesman_geometric.py-Instructions"></a>
This file contains the simulated annealing process for the traveling salesman problem using a numpy array of the x and y positions of all the targets in the area (in centimeters). 

### TravelingSalesman()<a name="TravelingSalesman()"></a>
A class that uses the numpy array of locations and a simulated annealing algorithm to attempt to optimize the shortest possible path to all the target locations.

![alt text](https://github.com/MoShekaramiz/Tello_Edu_Surrogated_Wind_Fram/blob/main/Readme_img/Simulated_Annealing_25.png)

#### plot()<a name="plot()"></a>

<details><summary>plot()</summary>
<p>
    
Plots the beginning path and optimized path for visual comparison and validation.

</p>
</details>

#### get_path()<a name="get_path()"></a>

<details><summary>get_path()</summary>
<p>
    
Returns the optimized path in the form of a numpy array.

</p>
</details>

#### energy_calc()<a name="energy_calc()"></a>

<details><summary>energy_calc()</summary>
<p>

Returns the total energy of the numpy array using the point-distance formula.

```python
xpos = np.array([0, 220, 100, 365])
xpos = np.append(xpos, xpos[0]) # X and Y arrays should begin and end with 0 to ensure a loop
ypos = np.array([0, 200, 78, 20])
ypos = np.append(ypos, ypos[0])
data = np.array([xpos, ypos], np.int32)

path = TravelingSalesman()
path.plot()
shortest_path = path.get_path()
path_energy = path.energy_calc(shortest_path)
```

</p>
</details>

## Tello IMU Calibration Instructions<a name="tello_imu_calibration"></a>
This video demonstrates how to calibrate the Inertial Measurement Unit (IMU) of Tello drones.

[![Tello IMU Calibration](https://github.com/angelrodriguez0617/Tello-Drone-Project/blob/angel_test_branch/Readme_img/Tello_IMU_Calibration_frame.jpg)](https://uvu365-my.sharepoint.com/:v:/g/personal/10801309_uvu_edu/EZEIaRa0uXJPqEB58yy91W4BHnJ7UpZLe9WT_pNogNW4og?e=Y0ydjm)

Video created by Brandon Pinney, former ECE student at UVU
</p>
</details>
